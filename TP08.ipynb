{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvdDBa1tIzYIpVqqZQ8EOS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsmarinho/pdscodes/blob/master/TP08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBtqbEQAk53p"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DeYl11T4Fbx"
      },
      "source": [
        "**TP08 - Processamento Digital de Imagens.**\n",
        "\n",
        "---\n",
        "\n",
        "O processamento digital de imagens é feito em duas dimensões, na dimensão *x* (colunas) e na dimensão *y* (linhas). Podemos considerar que uma linha/coluna é um sinal unidimensional e processar cada linha como um sinal unidimensional (em tons de cinza), como um sinal de audio, por exemplo.\n",
        "\n",
        "Procedimentos como filtragem, compactação, quantização podem ser considerados também como processamento de imagens. Cada amostra da imagem é chamada de pixel e a *densidade de píxels* pode ser considerada como uma boa analogia ao período de amostragem do sinal.\n",
        "\n",
        "Imagens coloridas implicam em diferentes graus de complexidade no processamento de imagens, e a utilização de diferentes [modelo de cores](https://en.wikipedia.org/wiki/Color_model) pode auxiliar no  processamento. Aqui utilizaremos apenas imagens preto e branco e coloridas no modelo de cor [RGB](https://en.wikipedia.org/wiki/RGB_color_model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMziVTRX39iC"
      },
      "source": [
        "# funcao matplotlib que le imagem lena512.png e carrega em\n",
        "# uma matriz RGB tridimensional [512,512,3]\n",
        "img = image.imread('/content/lena512.png')\n",
        "\n",
        "# algumas funcoes que podem auxiliar no programa, é sempre\n",
        "# bom conhecer algumas informações sobre o arquivo que está\n",
        "# sendo carregado\n",
        "\n",
        "print(img.dtype)\n",
        "print(img.shape)\n",
        "print(type(img))\n",
        "\n",
        "# o arquivo carregado têm os valores de amplitude do tipo\n",
        "# float32 que variam entre 0..1, para transformá-los em inteiros\n",
        "# basta proceder com a operação abaixo.\n",
        "print(np.floor(img[:3,:3]*255))\n",
        "\n",
        "# função que transforma uma imagem RGB em uma imagem p&b.\n",
        "# A função é uma combinação linear (produto interno) de\n",
        "# cada um dos valores R, G e B com o vetor [0.2989, 0.5870, 0.1140]\n",
        "# https://www.mathworks.com/help/matlab/ref/rgb2gray.html\n",
        "def rgb2gray(rgb):\n",
        "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E2d530KFv61"
      },
      "source": [
        "imgbw = rgb2gray(img)\n",
        "\n",
        "# lembre-se de utilizar o mapa de cores correto para\n",
        "# visualizar o tipo de imagem que você tem. Experimente\n",
        "# utilizar outros mapas de cores para obter outros\n",
        "# efeitos de visualização.\n",
        "plt.imshow(imgbw, cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz5-M-wAiuBx"
      },
      "source": [
        "# Em processamento de imagem geralmente utiliza-se a tranformada coseno\n",
        "# discreto ao invés da transformada de Fourier, por motivos dentre os \n",
        "# quais a DCT é melhor adaptada para aplicações de compressão. A DCT\n",
        "# é uma transformada relacionada à transformada de Fourier (Fourier-related)\n",
        "# Mais informações sobre a DCT pode ser encontrada em\n",
        "# https://en.wikipedia.org/wiki/Discrete_cosine_transform\n",
        "\n",
        "# Aqui definimos as funções DCT de tipo II e III, essas funções são operações\n",
        "# inversas uma da outra. Ou seja, a DCTIII é a transformada inversa da DCTII\n",
        "# e vice-e-versa\n",
        "\n",
        "def dctII(x):\n",
        "  N = len(x)\n",
        "\n",
        "  n = np.linspace(0, N-1, N)\n",
        "  e = lambda f: np.cos((np.pi/N) * (n + 0.5) * f)\n",
        "  \n",
        "  ft = np.zeros((N, N))\n",
        "  for k in range(N):\n",
        "    ft[:, k] = e(k) * x\n",
        "\n",
        "  return np.sum(ft, axis=0)\n",
        "\n",
        "def idctIII(x):\n",
        "  N = len(x)\n",
        "\n",
        "  n = np.linspace(0, N-1, N)\n",
        "  e = lambda f: np.cos((np.pi/N) * (f + 0.5) * n)\n",
        "  \n",
        "  ft = np.zeros((N, N))\n",
        "  for k in range(N):\n",
        "    ft[:, k] = e(k) * x\n",
        "    ft[0, k] = x[0] * 0.5\n",
        "\n",
        "  return np.sum(ft, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tznLN4nXJ5El"
      },
      "source": [
        "# Quantidade de samples utilizados para representação da imagem original\n",
        "# quanto menos samples, maior a compactação da imagem. Como a imagem lena\n",
        "# tem tamanho de 512x512, utilizar 254 samples significa uma compactação de 25%.\n",
        "\n",
        "# samples = int(np.floor(len(imgbw[0]) / 2)) # uses 256 samples for row/column\n",
        "# samples = int(np.floor(len(imgbw[0]) / 4)) # uses 128 samples for row/column\n",
        "samples = int(np.floor(len(imgbw[0]) / 8)) # uses 64 samples for row/column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Nhbi2_Trcg"
      },
      "source": [
        "# Outra maneira de zerar índices menos importantes da imagem é utilizando uma\n",
        "# função de threshold. Em python podemos utilizar as facilidades da linguagem\n",
        "# E gerar o mapeamento de índices dos valores da matriz que são menores ou \n",
        "# maiores do que determinado valor facilmente\n",
        "\n",
        "thresh = 0.01\n",
        "dct_thresh = DCT * (abs(DCT) > (thresh*np.max(DCT)))\n",
        "# print(DCT[0:20] * dct_thresh[0:20])\n",
        "\n",
        "percent_nonzeros = np.sum( dct_thresh != 0.0 ) / (imgbw.shape[0]*imgbw.shape[1]*1.0)\n",
        "print(\"Mantém apenas %f%% dos coeficientes DCT\" % (percent_nonzeros*100.0))\n",
        "\n",
        "abs(DCT[0:8,0:8]) > (thresh*np.max(DCT))\n",
        "\n",
        "# Esse é apenas um exemplo de como a eliminação de frequências não importantes\n",
        "# podem ser feitas, seguiremos com a remoção de frequências do caso anterior.\n",
        "# Ou seja, à partir da eliminação por faixa de frequência."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDASmNuHzi64"
      },
      "source": [
        "# O processo de compactação de imagem segue da seguinte forma:\n",
        "# 1. Calculo da DCT da imagem nos dois eixos (linha e coluna)\n",
        "# 2. Remove frequencias altas (com baixo nivel de energia)\n",
        "# 3. Calcula a IDCT para obter a imagem final\n",
        "\n",
        "# as variáveis abaixo são utilizadas para que cada fase do processo possa\n",
        "# ser visualizada, assim podemos ter uma idéia melhor do passo a passo\n",
        "# descrito acima.\n",
        "img_aux = np.zeros(imgbw.shape) # imagem original\n",
        "DCT = np.zeros(imgbw.shape)     # imagem DCT\n",
        "ci = np.zeros(imgbw.shape)      # imagem final compactada\n",
        "\n",
        "aux = np.zeros(imgbw.shape)     # matriz intermediario para calculo dct \n",
        "aux2 = np.zeros(imgbw.shape)    # matriz intermediario calculo idct\n",
        "\n",
        "# DCT\n",
        "for i in range(0, 512):\n",
        "  img_aux[i, :] = dctII(imgbw[i, :])\n",
        "for j in range(0, 512):\n",
        "  DCT[:, j] = dctII(img_aux[:, j])\n",
        "\n",
        "# IDCT\n",
        "for i in range(0, 512):\n",
        "  aux[i, 0:samples] = DCT[i, 0:samples]\n",
        "  aux[i, :] = idctIII(aux[i, :])\n",
        "\n",
        "for j in range(0, 512):\n",
        "  aux2[0:samples, j] = aux[0:samples, j]\n",
        "  ci[:, j] = idctIII(aux2[:, j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf_uoGA4QJi7"
      },
      "source": [
        "# Aqui normalizamos a imagem final para que os termos da matrix também fiquem\n",
        "# entre 0..1, tal qual a imagem original. Outra maneira mais interessante de\n",
        "# proceder com a normalização é usando as versões normalizadas da DCT, mas que\n",
        "# implica em mais operações de calculo e, portanto, mais tempo de execução.\n",
        "ci=ci/ci.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5knpJ4J4U6P"
      },
      "source": [
        "plt.imshow(np.hstack( (imgbw, ci) ), cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcGls5MynkAd"
      },
      "source": [
        "# A função dct que usamos até aqui serve bem para estudo e compreensão, \n",
        "# mas é muito lenta. Daqui para frente nesse TP se assegure que o modulo \n",
        "# scipy está instalado e utilize as funcoes dct2 e idct2 abaixo. \n",
        "# Ambas as funções são interfaces para a função dct do scipy, e que já\n",
        "# calcula a transformada em duas dimensões.\n",
        "from scipy.fftpack import dct, idct\n",
        "\n",
        "def dct2(imgGray, w):\n",
        "    DCT = dct(dct(imgGray, n=w, axis=0, norm='ortho'), n=w, axis=1, norm='ortho')\n",
        "    return DCT\n",
        "\n",
        "def idct2(DCT, w, f):\n",
        "    IDCT = idct(idct(DCT[0:f,0:f], n=w, axis=0, norm='ortho'), n=w, axis=1, norm='ortho')\n",
        "    return IDCT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxdPaNbsP7SQ"
      },
      "source": [
        "###Questões\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7EfVpxQLUd"
      },
      "source": [
        "**1.** Apesar do processo de compactação de imagem ter sido descrito acima, o normal é que a sequência não seja executada na matriz inteira. Antes de que a DCT seja calculada dividimos a matriz em submatrizes menores calculamos a DCT de cada submatriz.\n",
        "\n",
        "Divida a imagem em várias submatrizes de 8x8 e calcule a DCT de cada submatriz. Para isso não é preciso que submatrizes sejam geradas, você pode fazer isso utilizando indexação da matriz da imagem original. Essa etapa é conhecida como o cálculo dos blocos DCT.\n",
        "\n",
        "Após calcular as DCT, plote a matriz da DCT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIqsnKaySHPl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUmPXT1iSH2v"
      },
      "source": [
        "**2.** Remova (iguale a zero) metade das linhas e colunas de cada bloco DCT. OS blocos DCT deve ser diferente de zero apenas para os índices \\[0:4,0:4\\] após essa operação.\n",
        "\n",
        "Quando os blocos DCT for compactado, então calcule a DCT inversa e plote a imagem. Você deve terminar com uma versão compactada da imagem original.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kxrAHQmUgSI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKSME1t-XqRc"
      },
      "source": [
        "**3.** A compactação JPEG utiliza o mesmo procedimento descrito anteriormente para compactar as imagens. Entretanto, ao invés de remover algumas frequências, esse tipo de compactação utiliza matrizes de quantização para cada nível de compactação. \n",
        "\n",
        "Cada índice da matriz DCT compactada é calculado pela equação\n",
        "$$\n",
        "C_{i,j}=\\mbox{round}\\left(\\frac{D_{i,j}}{Q_{i,j}}\\right)\n",
        "$$\n",
        "onde $D_{i,j}$ são os índices da matriz de DCT e $Q_{i,j}$ os índices da matriz de quantização. \n",
        "\n",
        "Matrizes de quantização de 10% 50% e 90% estão descritas abaixo. Utilize essas matrizes para compactar a imagem da lena (p&b)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv_PlVJAaB7w"
      },
      "source": [
        "QJPEG10 =[[ 80,  60,  50,  80, 120, 200, 255, 255],\n",
        "          [ 55,  60,  70,  95, 130, 255, 255, 255],\n",
        "          [ 70,  65,  80, 120, 200, 255, 255, 255],\n",
        "          [ 70,  85, 110, 145, 255, 255, 255, 255],\n",
        "          [ 90, 110, 185, 255, 255, 255, 255, 255],\n",
        "          [120, 175, 255, 255, 255, 255, 255, 255],\n",
        "          [245, 255, 255, 255, 255, 255, 255, 255],\n",
        "          [255, 255, 255, 255, 255, 255, 255, 255]]\n",
        "\n",
        "QJPEG50 =[[16, 11, 10, 16,  24,  40,  51,  61],\n",
        "          [12, 12, 14, 19,  26,  58,  60,  55],\n",
        "          [14, 13, 16, 24,  40,  57,  69,  56],\n",
        "          [14, 17, 22, 29,  51,  87,  80,  62],\n",
        "          [18, 22, 37, 56,  68, 109, 103,  77],\n",
        "          [24, 35, 55, 64,  81, 104, 113,  92],\n",
        "          [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "          [72, 92, 95, 98, 112, 100, 103,  99]]\n",
        "\n",
        "QJPEG90 =[[3,   2,  2,  3,  5,  8, 10, 12],\n",
        "          [2,   2,  3,  4,  5, 12, 12, 11],\n",
        "          [3,   3,  3,  5,  8, 11, 14, 11],\n",
        "          [3,   3,  4,  6, 10, 17, 16, 12],\n",
        "          [4,   4,  7, 11, 14, 22, 21, 15],\n",
        "          [5,   7, 11, 13, 16, 12, 23, 18],\n",
        "          [10, 13, 16, 17, 21, 24, 24, 21],\n",
        "          [14, 18, 19, 20, 22, 20, 20, 20]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuJvz6G6aOI4"
      },
      "source": [
        "**4.** Faça o mesmo procedimento da questão anterior, agora para a imagem lena original (colorida)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV0L9yjeaNPq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}